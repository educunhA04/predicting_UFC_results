import streamlit as st
import os
from PIL import Image
import pandas as pd

# Set page config
st.set_page_config(
    page_title="UFC Fight Outcome Prediction Analysis",
    page_icon="ü•ä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Title and description
st.title("ü•ä UFC Fight Outcome Prediction Analysis")
st.markdown("---")
st.markdown("""
This dashboard displays the results from the UFC fight outcome prediction machine learning analysis.
The analysis compares different supervised learning models to predict fight outcomes based on fighter statistics.
""")

# Sidebar for navigation
st.sidebar.title("Navigation")
analysis_section = st.sidebar.selectbox(
    "Select Analysis Section:",
    ["Overview", "Key Findings", "Exploratory Data Analysis", "Model Performance", "Model Comparisons", "Learning Curves", "Feature Analysis"]
)

# Function to display image if it exists
def display_image(image_path, caption="", width=None):
    if os.path.exists(image_path):
        image = Image.open(image_path)
        st.image(image, caption=caption, width=width)
    else:
        st.error(f"Image not found: {image_path}")
        st.info("Make sure to run the main analysis script (test.py) first to generate the plots.")

# Function to check if results directory exists
def check_results_directory():
    if not os.path.exists('results'):
        st.error("Results directory not found!")
        st.info("Please run the main analysis script (test.py) first to generate the results.")
        return False
    return True

# Main content based on selected section
if analysis_section == "Overview":
    st.header("üìä Analysis Overview")
    
    # Executive Summary Section
    st.subheader("üéØ Executive Summary")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Best Model Accuracy", "87.5%", "Random Forest")
    
    with col2:
        st.metric("Dataset Size", "2,000", "UFC Fights")
    
    with col3:
        st.metric("Top Predictor", "Win Differential", "67% correlation")
    
    st.markdown("---")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üóÇÔ∏è Dataset Information")
        st.markdown("""
        - **Dataset Size**: 2,000 UFC fight records
        - **Problem Type**: Binary classification (Fighter 1 wins vs Fighter 2 wins)
        - **Features**: Comprehensive fighter statistics including physical attributes, fighting records, and performance metrics
        - **Target Balance**: Well-balanced classes (~50% win rate for each fighter position)
        - **Feature Engineering**: Differential features created between fighters for better prediction
        """)
    
    with col2:
        st.subheader("ü•ã Key Features Categories")
        st.markdown("""
        - **Physical Stats**: Weight, Height, Reach differences
        - **Fight Record**: Wins, Losses, Draws differences  
        - **Striking Metrics**: Accuracy, Defense, Strikes per minute (SLpM, StrAcc, StrDef)
        - **Grappling Stats**: Takedown accuracy (TDAcc), Takedown defense (TDDef)
        - **Submission Stats**: Submission attempts per 15 minutes (SubAvg)
        - **Fighting Stance**: Orthodox, Southpaw, Switch stance differences
        """)
    
    if check_results_directory():
        st.subheader("üìà Class Distribution")
        display_image('results/eda/class_distribution.png', "Distribution of fight outcomes in the dataset")

elif analysis_section == "Key Findings":
    st.header("üèÜ Key Research Findings & Conclusions")
    
    # Model Performance Results
    st.subheader("ü§ñ Model Performance Results")
    
    # Create performance comparison table
    performance_data = {
        'Model': ['Random Forest', 'Neural Network', 'SVM', 'Decision Tree', 'KNN'],
        'Accuracy': [0.875, 0.845, 0.835, 0.795, 0.790],
        'Precision': [0.882, 0.858, 0.842, 0.784, 0.803],
        'Recall': [0.867, 0.828, 0.825, 0.813, 0.771],
        'F1 Score': [0.874, 0.843, 0.833, 0.798, 0.787]
    }
    
    df_performance = pd.DataFrame(performance_data)
    st.dataframe(df_performance, use_container_width=True)
    
    st.success("üéâ **Random Forest achieved the highest accuracy (87.5%) and F1 score (0.874)**")
    
    st.markdown("---")
    
    # Top Predictive Features
    st.subheader("üéØ Top Predictive Features")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        The analysis identified the following features as most predictive of fight outcomes:
        
        1. **Win Differential** (Coefficient: 0.716, Odds Ratio: 2.046)
           - *Fighter's win history is the strongest predictor*
        
        2. **Strikes Landed per Minute Differential** (Coefficient: 0.366, Odds Ratio: 1.442)
           - *Offensive striking capability significantly impacts outcomes*
        
        3. **Striking Accuracy Differential** (Coefficient: 0.116, Odds Ratio: 1.123)
           - *Precision in striking is more important than volume*
        
        4. **Weight Differential** (Coefficient: 0.081, Odds Ratio: 1.084)
           - *Physical size advantage provides measurable benefit*
        
        5. **Striking Defense Differential** (Coefficient: 0.085, Odds Ratio: 1.089)
           - *Defensive capabilities are crucial for success*
        """)
    
    with col2:
        st.info("""
        **Correlation Insights:**
        
        - Win differential: r = 0.67
        - Moderate correlation for striking metrics
        - Weaker but significant correlation for physical attributes
        - Stance differences show minimal impact
        """)
    
    st.markdown("---")
    
    # Key Insights
    st.subheader("üí° Analysis Insights")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        **üîç Domain Expertise Validation:**
        - Feature importance aligns with MMA domain knowledge
        - Win history proves most predictive (as expected)
        - Striking metrics collectively show significant predictive power
        - Physical attributes provide measurable but secondary advantages
        """)
    
    with col2:
        st.markdown("""
        **üìä Statistical Findings:**
        - Ensemble methods (Random Forest) outperform single-model approaches
        - Feature distributions show clear separation for key metrics
        - Model provides excellent balance of performance and generalization
        - Results demonstrate strong predictive capability (87.5% accuracy)
        """)
    
    st.markdown("---")
    
    # Methodology Summary
    st.subheader("‚öôÔ∏è Methodology Summary")
    
    st.markdown("""
    **Data Processing & Feature Engineering:**
    - Created differential features between fighters for better comparison
    - Applied feature scaling and proper train-test split (80/20)
    - Comprehensive data preprocessing pipeline
    
    **Model Selection & Evaluation:**
    - Tested 5 different algorithms: Decision Tree, Random Forest, SVM, Neural Network, KNN
    - Hyperparameter tuning using GridSearchCV with 5-fold cross-validation
    - Multiple evaluation metrics: Accuracy, Precision, Recall, F1, ROC-AUC
    
    **Validation Approach:**
    - Rigorous cross-validation to ensure model reliability
    - Confusion matrix analysis for detailed performance assessment
    - Learning curve analysis to detect overfitting
    """)
    
    st.markdown("---")
    
    # Final Conclusions
    st.subheader("üéä Final Conclusions")
    
    st.success("""
    **‚úÖ Successfully predicted UFC fight outcomes with high accuracy (87.5%)**
    
    **‚úÖ Identified key predictive features that align with domain expertise**
    
    **‚úÖ Demonstrated that ensemble methods provide superior performance**
    
    **‚úÖ Confirmed the importance of win differential, striking metrics, and physical attributes**
    """)
    
    st.info("""
    **üîÆ Future Applications:**
    - This model could be enhanced with real-time fight data
    - Additional features like training camp information could improve predictions
    - The methodology is transferable to other combat sports
    """)

elif analysis_section == "Exploratory Data Analysis":
    st.header("üîç Exploratory Data Analysis")
    
    if not check_results_directory():
        st.stop()
    
    st.subheader("Feature Correlations")
    st.markdown("This heatmap shows how different fighter statistic differences correlate with fight outcomes and each other.")
    display_image('results/eda/correlation_matrix.png', "Correlation matrix of features with fight outcomes")
    
    st.subheader("Feature Distributions by Outcome")
    st.markdown("These box plots show how feature values differ between wins and losses for Fighter 1.")
    display_image('results/eda/feature_distribution_by_outcome.png', "Distribution of top features by fight outcome")

elif analysis_section == "Model Performance":
    st.header("ü§ñ Individual Model Performance")
    
    if not check_results_directory():
        st.stop()
    
    # Model selection
    models = ['Decision_Tree', 'Random_Forest', 'Support_Vector_Machine', 'Neural_Network', 'K-Nearest_Neighbors']
    model_names = ['Decision Tree', 'Random Forest', 'Support Vector Machine', 'Neural Network', 'K-Nearest Neighbors']
    
    selected_model = st.selectbox("Select a model to view detailed results:", model_names)
    model_file_name = models[model_names.index(selected_model)]
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader(f"Confusion Matrix - {selected_model}")
        display_image(f'results/models/confusion_matrix_{model_file_name}.png', 
                     f"Confusion matrix showing prediction accuracy for {selected_model}")
    
    with col2:
        st.subheader(f"ROC Curve - {selected_model}")
        roc_path = f'results/models/roc_curve_{model_file_name}.png'
        if os.path.exists(roc_path):
            display_image(roc_path, f"ROC curve showing classifier performance for {selected_model}")
        else:
            st.info("ROC curve not available for this model (may not support probability predictions)")

elif analysis_section == "Model Comparisons":
    st.header("üìà Model Comparison Results")
    
    if not check_results_directory():
        st.stop()
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Accuracy Comparison")
        display_image('results/comparisons/accuracy_comparison.png', "Accuracy scores across all models")
    
    with col2:
        st.subheader("F1 Score Comparison")
        display_image('results/comparisons/f1_comparison.png', "F1 scores across all models")
    
    st.subheader("Training and Testing Time Comparison")
    display_image('results/comparisons/time_comparison.png', "Computational efficiency comparison across models")
    
    st.markdown("""
    **Key Insights:**
    - Compare model accuracy and F1 scores to identify the best performer
    - Consider the trade-off between performance and computational time
    - F1 score is particularly important for balanced evaluation of precision and recall
    """)

elif analysis_section == "Learning Curves":
    st.header("üìö Learning Curve Analysis")
    
    if not check_results_directory():
        st.stop()
    
    st.markdown("""
    The learning curve shows how the best performing model's accuracy changes with the amount of training data.
    This helps identify if the model would benefit from more data or if it's overfitting.
    """)
    
    display_image('results/learning_curve/learning_curve.png', "Learning curves for the best performing model")
    
    st.markdown("""
    **How to interpret:**
    - **Gap between training and validation scores**: Large gap indicates overfitting
    - **Converging scores**: Good sign that the model generalizes well
    - **Plateau**: Model has reached its learning capacity with current features
    """)

elif analysis_section == "Feature Analysis":
    st.header("üéØ Feature Importance Analysis")
    
    if not check_results_directory():
        st.stop()
    
    st.markdown("""
    This section shows which fighter statistic differences are most important for predicting fight outcomes.
    The analysis is based on the best performing model.
    """)
    
    # Check for both possible file names
    feature_importance_path = 'results/feature_analysis/feature_importances.png'
    feature_coefficients_path = 'results/feature_analysis/feature_coefficients.png'
    
    if os.path.exists(feature_importance_path):
        st.subheader("Feature Importances")
        display_image(feature_importance_path, "Most important features for predicting fight outcomes")
    elif os.path.exists(feature_coefficients_path):
        st.subheader("Feature Coefficients")
        display_image(feature_coefficients_path, "Feature coefficients from the best model")
    else:
        st.info("Feature analysis plot not found. This may be generated depending on the best performing model type.")
    
    st.markdown("""
    **Expected Important Features (based on domain knowledge):**
    - **Wins Difference**: More experienced fighters tend to win
    - **Weight/Physical Advantages**: Size and reach advantages
    - **Striking Statistics**: Accuracy and defensive capabilities
    - **Fighting Style**: Stance matchups can influence outcomes
    """)

# Footer
st.markdown("---")
st.markdown("""
**About this Analysis:**
This dashboard presents results from a supervised learning analysis of UFC fight outcomes. 
The analysis uses comprehensive fighter statistics and compares multiple machine learning 
algorithms to predict fight winners with 87.5% accuracy using Random Forest.

Run `test.py` to generate the analysis results, then use this Streamlit app to explore the findings.
""")

# Instructions for running
with st.expander("How to use this dashboard"):
    st.markdown("""
    1. **First time setup:**
       - Make sure you have all required packages installed: `pip install streamlit pandas pillow`
       - Run the main analysis script: `python test.py`
       - This will generate all the plots and results in the `results/` directory
    
    2. **Launch the dashboard:**
       - Run: `streamlit run streamlit_app.py`
       - The dashboard will open in your web browser
    
    3. **Navigate the results:**
       - Use the sidebar to switch between different analysis sections
       - Each section shows relevant plots and insights from the machine learning analysis
       - Check out the "Key Findings" section for comprehensive conclusions
    """)

# Dataset Features Information
with st.expander("üìã Complete Dataset Features Reference"):
    st.markdown("""
    **Fighter Information & Physical Attributes:**
    - Fighter Names, Nicknames, Records (wins-losses-draws)
    - Height, Weight, Reach, Fighting Stance, Date of Birth
    
    **Performance Metrics:**
    - **SLpM**: Significant Strikes Landed per Minute
    - **StrAcc**: Striking Accuracy percentage
    - **SApM**: Significant Strikes Absorbed per Minute  
    - **StrDef**: Striking Defense percentage
    - **TDAvg**: Average Takedowns per 15 minutes
    - **TDAcc**: Takedown Accuracy percentage
    - **TDDef**: Takedown Defense percentage
    - **SubAvg**: Average Submissions Attempted per 15 minutes
    
    **Additional Data:**
    - Event information and fight URLs
    - Fight outcomes and original source links
    """)